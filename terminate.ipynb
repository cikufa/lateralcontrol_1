{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "terminate.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNk1Y2gDWC4EgOVJIImeXrH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cikufa/lateralcontrol_1/blob/main/terminate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pm5Vog9rQ3f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VVh3mWPIJyp",
        "outputId": "2ac65f2a-86da-4d06-b55d-cd8fcde6fdb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xlsxwriter in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "#saarhin\n",
        "#tasks: 1-action , preview dist in in reward/ 2- one step ahead in network input/ 3- reward every 5 iteration \n",
        "import numpy as np \n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import shapely.geometry as geom\n",
        "from shapely.ops import nearest_points\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam_v2\n",
        "import tensorflow_probability as tfp\n",
        "import os\n",
        "from keras.layers import Dense\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter\n",
        "#from keras.optimizers import adam\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hbQ0B2DcIOs4"
      },
      "outputs": [],
      "source": [
        "class GenericNetwork(keras.Model):\n",
        "    def __init__(self, n_actions, fc1_dims, fc2_dims, name, chkpt_dir=\"/tmp/actor_critic\"):\n",
        "        super(GenericNetwork, self).__init__()\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        self.model_name = name\n",
        "        self.checkpoint_dir = chkpt_dir\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, name)\n",
        "\n",
        "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
        "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
        "        self.fc3 = Dense(n_actions)\n",
        "        \n",
        "        #self.v = Dense(1, activation=None)\n",
        "        #continous action is represented as a normal distribution that is characterized with 2 quantities: a mean and a standard deviation \n",
        "        #self.pi = Dense(n_actions=2, activation='softmax')\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2e_3NTEAbhqu"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, layer1_dim=128, layer2_dim=64, n_actions=2, alpha_A=0.00003, alpha_C=0.00005, gamma=0.99):\n",
        "        self.layer1_dim = layer1_dim\n",
        "        self.layer2_dim = layer2_dim\n",
        "        self.n_actions = n_actions\n",
        "        self.gamma = gamma\n",
        "        self.alpha_A = alpha_A \n",
        "        self.alpha_C= alpha_C\n",
        "        self.action = None\n",
        "        self.log_prob= None\n",
        "        \n",
        "        self.actor = GenericNetwork(n_actions, layer1_dim, layer2_dim, \"actor\")\n",
        "        self.actor.compile(optimizer=adam_v2.Adam(learning_rate=alpha_A))\n",
        "        self.critic = GenericNetwork(1, layer1_dim, layer2_dim, \"critic\")\n",
        "        self.critic.compile(optimizer=adam_v2.Adam(learning_rate=alpha_C))\n",
        "        self.aloss= []\n",
        "        self.closs=[]\n",
        "\n",
        "    def choose_action(self, observation): #obs shape (1,2)\n",
        "        state = tf.convert_to_tensor([observation]) #state shape (1,1,2)\n",
        "        pars= self.actor(state) #mean and standard deviation that make action probs\n",
        "        pars= np.asarray(tf.squeeze(pars)).reshape(1,2)  \n",
        "        sigma , mu = np.hsplit(pars , 2)\n",
        "        sigma = tf.exp(sigma) #get rid of negative sigma\n",
        "        #sigma= abs(sigma)\n",
        "        action_probabilities = tfp.distributions.Normal(mu , sigma) #normal distribution with mu,sigma pars  \n",
        "        #log_prob = action_probabilities.log_prob(action_probabilities) #log (gonna be used for gradient)\n",
        "        action = action_probabilities.sample() #choose action (most likely to be chosen with higher probability)\n",
        "        action = tf.tanh(action) * 0.07 #action: continuous num in range(-0.07, 0.07)((-4,4) degree_\n",
        "        self.action = action  \n",
        "        return action #cast tensor to numpy(openAI gym doesnt take tensor)\n",
        "\n",
        "    # def save_models(self):\n",
        "    #     #print('... saving models ...')\n",
        "    #     self.actor.save_weights(self.actor.checkpoint_file)\n",
        "    #     self.critic.save_weights(self.critic.checkpoint_file)\n",
        "    # def load_models(self):\n",
        "    #     print('... loading models ...')\n",
        "    #     self.actor.load_weights(self.actor.checkpoint_file)\n",
        "    #     self.critic.load_weights(self.critic.checkpoint_file)\n",
        "        \n",
        "    def learn(self, state, reward, state_,done):\n",
        "        #print(\"state before \")\n",
        "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
        "        state_ = tf.convert_to_tensor([state_], dtype=tf.float32)\n",
        "        reward = tf.convert_to_tensor(reward, dtype=tf.float32) # not fed to NN -> no need to reshape\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            state_value = self.critic(state)\n",
        "            state_value_ = self.critic(state_)\n",
        "            state_value = tf.squeeze(state_value) #squeeze Removes dims of size 1 from the shape of a tensor.\n",
        "            state_value_ = tf.squeeze(state_value_)\n",
        "            pars= self.actor(state)\n",
        "            #pars= np.asarray(tf.squeeze(pars)).reshape(1,2)\n",
        "            #mu , sigma= np.hsplit(pars , 2)\n",
        "            #mu = np.squeeze(mu)\n",
        "            #sigma = np.squeeze(sigma)\n",
        "            mu = pars[0,0]\n",
        "            sigma = pars[0,1]\n",
        "            #print(sigma)\n",
        "            #sigma = tf.exp(sigma)\n",
        "            #print(sigma)\n",
        "            action_probs = tfp.distributions.Normal(mu, abs(sigma)) #policy \n",
        "            log_prob = action_probs.log_prob(self.action[0,0] )\n",
        "            #print(mu,sigma)\n",
        "            #print(log_prob)\n",
        "                      \n",
        "            #TD error: \n",
        "            TD= self.gamma*state_value_*(1-int(done)) - state_value \n",
        "            delta = reward + TD #1-done: terminal stRemoves dimensions of size 1 from the shape of a tensor.ate zero effect \n",
        "            actor_loss = (-log_prob*delta)            \n",
        "            critic_loss = (delta**2) \n",
        "            #print(\"sig\", sigma , \"ac\", actor_loss, \"cr\", critic_loss)\n",
        "  \n",
        "            \n",
        "        gradient1 = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "        \n",
        "        self.actor.optimizer.apply_gradients((grad , var) for (grad , var) in zip(gradient1, self.actor.trainable_variables) if grad is not None)\n",
        "        #if grad is not None\n",
        "            \n",
        "        gradient2 = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients((grad , var) for (grad , var) in zip(gradient2, self.critic.trainable_variables) if grad is not None)\n",
        "        # if grad is not None\n",
        "        return critic_loss, actor_loss, gradient1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "id": "-7jAXNqRskpg"
      },
      "outputs": [],
      "source": [
        "class lateralenv:\n",
        "    def __init__(self, data, data_length, n_episodes, episode_length):\n",
        "        # constants\n",
        "        dt = 0.01\n",
        "        vx = 10\n",
        "        iz = 2278.8\n",
        "        m = 1300\n",
        "        a1 = 1;\n",
        "        a2 = 1.5\n",
        "        caf = 60000\n",
        "        car = 60000\n",
        "        cb = -(caf + car);\n",
        "        cr = (-a1 * caf + a2 * car) / vx\n",
        "        db = -(a1 * caf - a2 * car);\n",
        "        dr = -(a1 ** 2 * caf + a2 ** 2 * car) / vx\n",
        "        cd = caf;\n",
        "        dd = a1 * caf\n",
        "        self.constants = [dt, vx, iz, m, cb, cr, db, dr, cd, dd]\n",
        "\n",
        "        self.data_length = data_length\n",
        "        self.n_episodes = n_episodes\n",
        "        self.episode_length = episode_length\n",
        "        self.episode_length_cnt = episode_length\n",
        "        \n",
        "        self.road = data[0:data_length, :]\n",
        "        self.x = data[0:data_length, 0]\n",
        "        self.y = data[0:data_length, 1]\n",
        "       \n",
        "        self.heading_angle = [np.arctan2(self.y[i + 1] - self.y[i], self.x[i + 1] - self.x[i]) for i in\n",
        "                         range(self.data_length-1)] # rad [-1.57, 1.57]\n",
        "        self.heading_angle.insert(0, self.heading_angle[0])  # append last value to adjust the shape\n",
        "        self.heading_angle = np.asfarray(self.heading_angle).reshape(self.data_length, 1)\n",
        "\n",
        "        # ______________________________________________init vars_____________________________________________________________\n",
        "     \n",
        "        self.score = 0\n",
        "        self.index = 0\n",
        "        self.Done = 0\n",
        "        self.coordinates = []\n",
        "        self.nearestPiontCheck = []\n",
        "        self.vys = []\n",
        "        self.vymax = -10\n",
        "        self.vars = np.zeros((5, 1))\n",
        "        self.vars_ = np.zeros((5, 1), dtype='float64')  # is only updated for normal step\n",
        "        self.vars_tmp= np.zeros((5, 1)) # is updated for both normal step and preview step\n",
        "\n",
        "    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "    def dist_diff(self, ep, limit_dist, limit_ang, stp, pre_point=geom.Point(0,0)):\n",
        "        vy, r, x, y, psi = self.vars_tmp\n",
        "        ##1: based on where the car is supposed to be on this iteration\n",
        "        # self.index = self.index+1\n",
        "        # dist = self.data[self.index, 0:2] - coordinate_ #(1,2)\n",
        "        # angle_diff= self.data[self.index,2] - psi_\n",
        "        # ________________________________________________________________________\n",
        "\n",
        "        ## 2: based on where the car is supposed to be if the driven distance was along the road\n",
        "        # driving_distance= (vy**2 + vx**2)**0.5 *dt #driving angle : psi_\n",
        "        # #(dx^2+dy^2)^0.5= distance , dy=1.5dx -> (3.25dx^2)*0.5 = distance -> 1.802 dx = distance\n",
        "        # dx= driving_distance / math.sqrt(3.25); dy= dx*1.5\n",
        "        # dist= ((dx - x_)**2 + (dy- y_)**2)**0.5\n",
        "        # angle_diff =\n",
        "        # _______________________________________________________________________\n",
        "\n",
        "        # 3: based on car's vertical disance with the road\n",
        "        point = geom.Point(x, y)\n",
        "        dist = point.distance(self.road_ep)\n",
        "        #dist_z = math.sqrt((y - self.y0) ** 2 + (x - self.x0) ** 2)\n",
        "        limited_dist = max(dist, 0.01)\n",
        "        limited_dist = min(limited_dist, 100)\n",
        "\n",
        "        nearestP = nearest_points(self.road_ep, point)[0]\n",
        "        self.nearestPiontCheck.append(np.array(nearestP))\n",
        "        self.nearestPiontCheck.append(np.array(point))\n",
        "        road_slope = (nearestP.y-pre_point.y)/(nearestP.x-pre_point.x) if (nearestP.x-pre_point.x) !=0 else (nearestP.y-pre_point.y)/0.001\n",
        "        angle_diff = abs(np.arctan2((road_slope-psi), 1))[0]\n",
        "        #angle_diff = abs(np.arctan2((nearestP.y-pre_point.y),nearestP.x-pre_point.x)- psi[0]) #sara \n",
        "\n",
        "        #index, = np.where(self.road_ep == nearestP)\n",
        "        # print(\"index\", index)\n",
        "        #angle_diff=  np.arctan2(self.road_ep[index+1][1]-self.road_ep[index][1], self.road_ep[index+1][0]- self.road_ep[index][0]) - psi\n",
        "        # angle_diff = abs((np.cos(x / 100) / 4 - psi)[0])\n",
        "        limited_angle_diff = max(angle_diff, 0.005)\n",
        "        # limited_angle_diff=min(limited_angle_diff , 100) #-> max reward = 5000, min reward 5e-5\n",
        "\n",
        "        if limit_dist == 1:\n",
        "            if limit_ang == 1:\n",
        "                return limited_dist, limited_angle_diff, nearestP\n",
        "            elif limit_ang == 0:\n",
        "                return limited_dist, angle_diff, nearestP\n",
        "        else:\n",
        "            return dist, angle_diff, nearestP\n",
        "\n",
        "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "    def preview(self, action,\n",
        "                preview):  # in this version the preview point is calculated using the updated self.vars. also try with non-updated vars\n",
        "        dt, vx, iz, m, cb, cr, db, dr, cd, dd = self.constants\n",
        "        vy, r, x, y, psi = np.vsplit(self.vars, 5)\n",
        "        if preview == 1:\n",
        "            dt = 0.3\n",
        "        if preview == 0:\n",
        "            dt = 0.1\n",
        "        # calc new state\n",
        "        par_mat1 = np.array([[cb / (m * vx), cr / m - vx, 0, 0, 0],\n",
        "                             [db / (iz * vx), dr / iz, 0, 0, 0],\n",
        "                             [-math.sin(psi), 0, 0, 0, 0],\n",
        "                             [math.cos(psi), 0, 0, 0, 0],\n",
        "                             [0, 1, 0, 0, 0]])\n",
        "\n",
        "        par_mat2 = np.array([[cd * action / m], [dd * action / iz], [vx * math.cos(psi)],\n",
        "                             [vx * math.sin(psi)], [0]], dtype='float64')\n",
        "\n",
        "        var_dot_mat = par_mat1 @ self.vars + par_mat2  # (5,1)= (5,5)@(5,1)+(5,1)\n",
        "        self.vars_tmp = self.vars + dt * var_dot_mat  # (5,1) =(5,1)+(5,1)\n",
        "\n",
        "        if preview == 0:\n",
        "            self.vars_ = self.vars_tmp\n",
        "\n",
        "        return\n",
        "\n",
        "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "    def normalize(self, d, a):\n",
        "        return d/(dist_limit-0), a/(ang_limit1-ang_limit2)\n",
        "\n",
        "    def step(self, action, stp_cnt, pre_point):\n",
        "        self.preview(action, preview=0)\n",
        "        # print(\"____________________________NOT preview_________________________\")\n",
        "        dist, angle_diff, pre_point = lateralenv.dist_diff(self, ep=0, limit_dist=1, limit_ang=0, stp=stp_cnt, pre_point=pre_point)\n",
        "        dist, angle_diff= self.normalize(d=dist, a=angle_diff)\n",
        "        #print(\"140 step :  dist\" , dist, \"angle\", angle_diff, \"Z  \", pre_point)\n",
        "        self.preview(action, preview=1)\n",
        "        # print(\"____________________________preview______________________________\")\n",
        "        future_dist, future_angle_diff, _ = lateralenv.dist_diff(self, ep=0, limit_dist=1, limit_ang=0,\n",
        "                                                                             stp=stp_cnt)\n",
        "        future_dist, future_angle_diff= self.normalize( d= future_dist, a=future_angle_diff)\n",
        "\n",
        "        self.episode_length_cnt = self.episode_length_cnt - 1\n",
        "      \n",
        "        if dist > dist_limit or angle_diff > ang_limit1 or angle_diff<ang_limit2 or self.episode_length_cnt == 0:\n",
        "            self.Done = 1\n",
        "            #return self.vars_, self.state_,  bad_reward, 'nothing' , self.Done, pre_point\n",
        "            return None, None,  bad_reward, 'nothing' , self.Done, None\n",
        "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% calc reward %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "        # 3: based on car's vertical disance with the road\n",
        "        else:\n",
        "          weight = 1\n",
        "          action_weight = -10\n",
        "          preview_weight = 0.01\n",
        "          # print(\"point\", point, dist, \"ang\", angle_diff)\n",
        "          # print(\"dist\", dist, \"ang\", angle_diff)\n",
        "          k1 = 1 / (dist ** 2 + angle_diff ** 2)\n",
        "          k2 = 1 / (future_dist ** 2 + future_angle_diff ** 2)\n",
        "          ep_len_weight = 1\n",
        "          reward_calc = f'{weight} * {k1} + {preview_weight}*{k2} + {action_weight} * {action} + {ep_len_weight} * {ep_length}'\n",
        "          # reward = - angle_diff\n",
        "\n",
        "          ## 4: Sarah test\n",
        "          # ------------------------\n",
        "          reward = k1 * weight + k2 * preview_weight + action_weight * action + ep_len_weight *(max_ep_length -self.episode_length_cnt)\n",
        "        \n",
        "          # print(\"dist\", dist,\"angd\", angle_diff, \"p dist\",future_dist, \"p angd\", future_angle_diff)\n",
        "          self.state_ = np.array([dist, angle_diff, future_dist, future_angle_diff])  # real state (not limited)\n",
        "          # self.state_ = np.array([dist, angle_diff]) #real state (not limited)\n",
        "          \n",
        "          # for next step\n",
        "          self.vars = self.vars_\n",
        "          self.coordinates.append(self.vars[2:4, 0])\n",
        "          self.vys.append(self.vars[0])\n",
        "\n",
        "          return self.vars_, self.state_, reward, reward_calc, self.Done, pre_point  # state:(dist, ang_dif)\n",
        "\n",
        "    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "    def render(self, ep, score):\n",
        "        plt.xlabel(\"x\")\n",
        "        plt.ylabel(\"y\")\n",
        "        plt.plot(self.road_ep.coords.xy[0][:], self.road_ep.coords.xy[1][:], 'r') #road\n",
        "        if ep_length != 0:\n",
        "          plt.plot(np.array(self.coordinates)[:, 0], np.array(self.coordinates)[:, 1], label=score)  # path\n",
        "          b=1\n",
        "        if ep%5 ==0 and b == 1:\n",
        "         #plt.legend()\n",
        "          #plt.show()\n",
        "          plt.savefig(f\"drive/MyDrive/RL_lane_following_debug/paths/path{ep}.jpg\")\n",
        "          plt.cla()  \n",
        "          b=0 \n",
        "        \n",
        "    def reset(self, ep_pointer):  # before each episode\n",
        "        self.Done = 0\n",
        "        self.episode_length_cnt = max_ep_length\n",
        "        self.coordinates = []\n",
        "        self.nearestPiontCheck = []\n",
        "\n",
        "        # a new section of the road excel is selected for each episode\n",
        "        print(\"211ep pointer\", ep_pointer)\n",
        "        data_ep= self.road[ep_pointer:ep_pointer + int(max_ep_length/res), :]\n",
        "        self.road_ep = geom.LineString(zip(self.x[ep_pointer : ep_pointer + int(max_ep_length / res)], \n",
        "                                        self.y[ep_pointer : ep_pointer + int(max_ep_length / res)])) #500*2\n",
        "                                    \n",
        "        # the car starts on the road\n",
        "        st_vy = 0; st_r=0;\n",
        "        st_x = data_ep[0,0] #+ np.random.rand()\n",
        "        #st_x = self.road[ep_pointer:ep_pointer+1,0]\n",
        "        st_y = data_ep[0,1] #+ np.random.rand()\n",
        "        #st_y = self.road[ep_pointer+ep_pointer+1,1]\n",
        "        st_psi = self.heading_angle[ep_pointer] #+ np.random.rand()*0.01\n",
        "        st_pre_point = geom.Point(st_x, st_y)\n",
        "        \n",
        "        self.vars = np.array([[st_vy, st_r, st_x, st_y, st_psi]], dtype='float64').T\n",
        "        self.vars_tmp = np.array([[st_vy, st_r, st_x, st_y, st_psi]], dtype='float64').T # is updated for both normal step and preview step\n",
        "        \n",
        "        #point0_ep = geom.Point(st_x, st_y)\n",
        "        limited_dist0, limited_angle_diff0, _ = self.dist_diff(ep=0, limit_dist=1, limit_ang=0, stp=0)\n",
        "        self.preview(action=0, preview=1)\n",
        "        future_limited_dist0, future_limited_ang0, _ = self.dist_diff(ep=0, limit_dist=1, limit_ang=0, stp=0)  # sefr\n",
        "        \n",
        "        state0_ep = np.array([limited_dist0, limited_angle_diff0, limited_dist0, limited_angle_diff0])  # (1,4)\n",
        "    \n",
        "        return state0_ep, st_pre_point"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = 'drive/MyDrive/RL_lane_following_debug/Chaos-generted road.csv'\n",
        "road = pd.read_csv(uploaded).to_numpy()\n",
        "plt.plot(road[0:114,0],road[0:114,1])\n",
        "plt.plot(road[114:350,0], road[114:350,1])\n",
        "plt.plot(road[350:423,0], road[350:423,1])\n",
        "plt.show()\n",
        "plt.savefig('drive/MyDrive/RL_lane_following_debug/tets.png')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gauHF6SIViZz",
        "outputId": "a8e44556-4751-4681-c9e0-e9bb4eacd02d"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fw_1Aum5snkq",
        "outputId": "f2e7383c-2061-4584-ed52-85c362c5a0fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "211ep pointer 0\n",
            "episode 1 ep length  141 score [[266205.3]] avg_score 375349.47\n",
            "211ep pointer 17\n",
            "episode 2 ep length  438 score [[118632.73]] avg_score 447480.44\n",
            "211ep pointer 71\n",
            "episode 3 ep length  390 score [[80114.586]] avg_score 402469.25\n",
            "211ep pointer 119\n",
            "episode 4 ep length  253 score [[36360.527]] avg_score 324849.97\n",
            "211ep pointer 150\n",
            "episode 5 ep length  46 score [[1102.0607]] avg_score 259981.38\n",
            "211ep pointer 155\n",
            "episode 6 ep length  183 score [[17162.719]] avg_score 221885.77\n",
            "211ep pointer 177\n",
            "episode 7 ep length  92 score [[5177.6343]] avg_score 190868.28\n",
            "211ep pointer 188\n",
            "episode 8 ep length  37 score [[1702.721]] avg_score 167088.5\n",
            "211ep pointer 192\n",
            "episode 9 ep length  54 score [[1518.026]] avg_score 148614.19\n",
            "211ep pointer 198\n",
            "episode 10 ep length  82 score [[3958.605]] avg_score 134077.38\n",
            "211ep pointer 208\n",
            "episode 11 ep length  0 score 0 avg_score [[121888.52]]\n",
            "211ep pointer 208\n",
            "episode 12 ep length  0 score 0 avg_score [[111731.15]]\n",
            "211ep pointer 208\n",
            "episode 13 ep length  0 score 0 avg_score [[103136.445]]\n",
            "211ep pointer 208\n",
            "episode 14 ep length  0 score 0 avg_score [[95769.555]]\n",
            "211ep pointer 208\n",
            "episode 15 ep length  0 score 0 avg_score [[89384.914]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-105-524a23a731e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'episode'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ep length '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mep_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'avg_score'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mavg_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mworkbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-103-090e5f87d56c>\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, ep, score)\u001b[0m\n\u001b[1;32m    181\u001b[0m           \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoordinates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m           \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mep\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m5\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m          \u001b[0;31m#plt.legend()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m           \u001b[0;31m#plt.show()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'b' referenced before assignment"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "agent = Agent(layer1_dim=128, layer2_dim=64, n_actions=2, alpha_A=0.0003, alpha_C=0.005, gamma=0.99)\n",
        "n_episodes = 300\n",
        "data_length = int(road.shape[0]/10) #10,000\n",
        "max_ep_length = 500 # could be int(data_length / n_episodes) \n",
        "env = lateralenv(road, data_length, n_episodes, max_ep_length)\n",
        "\n",
        "cnt = 0\n",
        "dist_limit = 5\n",
        "ang_limit1 = 0.79; ang_limit2= -0.79; #45 degree\n",
        "bad_reward = 0 \n",
        "res = 8\n",
        "b=0 # for render \n",
        "score_history = []\n",
        "best_score = 0  # reward = 1/positive > 0 -> min score =0\n",
        "load_checkpoint = False\n",
        "\n",
        "workbook = xlsxwriter.Workbook('drive/MyDrive/RL_lane_following_debug/log.xlsx')\n",
        "log = workbook.add_worksheet(\"ep_per_ep\")\n",
        "log.write(0, 0, \"ep / step\")\n",
        "log.write(0, 3, \"vy\")\n",
        "log.write(0, 4, \"point\")\n",
        "log.write(0, 5, \"distance\")\n",
        "log.write(0, 6, \"angle_diff\")\n",
        "log.write(0, 7, \"road derivative\")\n",
        "log.write(0, 8, \"psi\")\n",
        "log.write(0, 9, \"reward\")\n",
        "log.write(0, 10, \"point dist_diff +  preview point dist_diff + action\")\n",
        "\n",
        "# training________________________________________________________________________________________\n",
        "ep_pointer= 0\n",
        "for ep in range(1, n_episodes + 1):\n",
        "    score = 0\n",
        "    al = [];\n",
        "    cl = [];\n",
        "    rewards = []\n",
        "    state, pre_point = env.reset(ep_pointer)  # (1,2)\n",
        "\n",
        "    states_ = []\n",
        "    ep_length= 0\n",
        "    #print(ep, \":____________________________________________________________________________\")\n",
        "    while True:\n",
        "        action = agent.choose_action(state)\n",
        "        # assert action != act_buffer , \"equal actions !!\"\n",
        "        #act_buffer = action\n",
        "\n",
        "        newvars, state_, reward, reward_calc, Done, pre_point = env.step(action, ep_length, pre_point)\n",
        "        if Done==1:\n",
        "          break\n",
        "        # if ep_length >100:\n",
        "        #   break\n",
        "        else:\n",
        "          states_.append(state_)\n",
        "          reward= tf.get_static_value(reward) \n",
        "          score = score + reward\n",
        "          rewards.append(reward)\n",
        "\n",
        "          # if not load_checkpoint:\n",
        "          closs, aloss, grad1 = agent.learn(state, reward, state_, Done)\n",
        "          # log\n",
        "          log.write(ep_pointer + ep_length + 1, 0, f\"{ep} / {ep_length}\")\n",
        "          log.write(ep_pointer + ep_length + 1, 3, newvars[0])\n",
        "          log.write(ep_pointer + ep_length + 1, 4, str(newvars[2:4]))\n",
        "          log.write(ep_pointer + ep_length + 1, 5, state_[0])\n",
        "          log.write(ep_pointer + ep_length + 1, 6, state_[1])\n",
        "          log.write(ep_pointer + ep_length + 1, 7, np.cos(newvars[2] / 200)[0] / 4)\n",
        "          log.write(ep_pointer + ep_length + 1, 8, newvars[-1])\n",
        "          log.write(ep_pointer + ep_length + 1, 9, reward)\n",
        "          log.write(ep_pointer + ep_length + 1, 10, reward_calc)\n",
        "\n",
        "          state = state_\n",
        "          ep_length += 1  # step counter\n",
        "    states_ = np.array(states_)\n",
        "    score_history.append(score* ep_length/100) # ep length should affect score \n",
        "    ep_pointer += int(ep_length/res)\n",
        "  \n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "    if (ep % 1 == 0):\n",
        "        print('episode', ep, 'ep length ', ep_length, 'score', score, 'avg_score', avg_score)\n",
        "        env.render(ep, score)\n",
        "\n",
        "workbook.close()\n",
        "\n",
        "if not load_checkpoint:\n",
        "    ep = [i + 1 for i in range(n_episodes)]\n",
        "    x = np.array(ep).reshape(n_episodes, 1)\n",
        "    score_history = np.array(score_history).reshape(n_episodes, 1)\n",
        "    plt.xlabel(\"episode\")\n",
        "    plt.ylabel(\"score\")\n",
        "    plt.plot(x, score_history)\n",
        "    plt.savefig('scores.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2Trps2XXUlHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmPtNVj3Px5c"
      },
      "outputs": [],
      "source": [
        "# test \n",
        "import numpy as np \n",
        "import math\n",
        "import shapely.geometry as geom\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.ops import nearest_points\n",
        "\n",
        "# x= np.arange(0, 10).reshape(10, 1) \n",
        "# y= 50*np.sin(x/200)\n",
        "# road = geom.LineString(zip(x,y))\n",
        "# p= geom.Point(314,50)\n",
        "# print(\"ggg\", p.coords[0][1])\n",
        "# print(\"ggg\", p.coords[0][0])\n",
        "# dist = p.distance(road) \n",
        "# print(dist)\n",
        "# nearestP = nearest_points(road, p)\n",
        "# print(nearestP[0])\n",
        "#angle_diff= np.arctan2(nearestP.centroid.y, nearestP.centroid.x) - self.psi0 #pos/neg mide  \n",
        "\n",
        "n= 25000\n",
        "x= np.arange(0, n).reshape(n, 1) \n",
        "y= 50*np.sin(x/100)\n",
        "plt.plot(x,y)\n",
        "#self.road = geom.LineString(zip(x,y))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "3CWXkoLX8O5X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}