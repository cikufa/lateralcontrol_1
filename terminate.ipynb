{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cikufa/lateralcontrol_1/blob/shekoufeh/terminate.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pm5Vog9rQ3f"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VVh3mWPIJyp",
        "outputId": "a0c3bf69-dd9b-4b44-a2d0-0465f90ff10c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.0.3-py3-none-any.whl (149 kB)\n",
            "\u001b[K     |████████████████████████████████| 149 kB 4.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.0.3\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# libraries\n",
        "#saarhin\n",
        "#tasks: 1-action , preview dist in in reward/ 2- one step ahead in network input/ 3- reward every 5 iteration \n",
        "import numpy as np \n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import shapely.geometry as geom\n",
        "from shapely.ops import nearest_points\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.optimizers import adam_v2\n",
        "import tensorflow_probability as tfp\n",
        "import os\n",
        "from keras.layers import Dense\n",
        "!pip install xlsxwriter\n",
        "import xlsxwriter\n",
        "#from keras.optimizers import adam\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hbQ0B2DcIOs4"
      },
      "outputs": [],
      "source": [
        "class GenericNetwork(keras.Model):\n",
        "    def __init__(self, n_actions, fc1_dims, fc2_dims, name, chkpt_dir=\"/tmp/actor_critic\"):\n",
        "        super(GenericNetwork, self).__init__()\n",
        "        self.fc1_dims = fc1_dims\n",
        "        self.fc2_dims = fc2_dims\n",
        "        self.n_actions = n_actions\n",
        "        self.model_name = name\n",
        "        self.checkpoint_dir = chkpt_dir\n",
        "        self.checkpoint_file = os.path.join(self.checkpoint_dir, name)\n",
        "\n",
        "        self.fc1 = Dense(self.fc1_dims, activation='relu')\n",
        "        self.fc2 = Dense(self.fc2_dims, activation='relu')\n",
        "        self.fc3 = Dense(n_actions)\n",
        "        \n",
        "        #self.v = Dense(1, activation=None)\n",
        "        #continous action is represented as a normal distribution that is characterized with 2 quantities: a mean and a standard deviation \n",
        "        #self.pi = Dense(n_actions=2, activation='softmax')\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.fc1(state)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "2e_3NTEAbhqu"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, layer1_dim=128, layer2_dim=64, n_actions=2, alpha_A=0.00003, alpha_C=0.00005, gamma=0.99):\n",
        "        self.layer1_dim = layer1_dim\n",
        "        self.layer2_dim = layer2_dim\n",
        "        self.n_actions = n_actions\n",
        "        self.gamma = gamma\n",
        "        self.alpha_A = alpha_A \n",
        "        self.alpha_C= alpha_C\n",
        "        self.action = None\n",
        "        self.log_prob= None\n",
        "        \n",
        "        self.actor = GenericNetwork(n_actions, layer1_dim, layer2_dim, \"actor\")\n",
        "        self.actor.compile(optimizer=adam_v2.Adam(learning_rate=alpha_A))\n",
        "        self.critic = GenericNetwork(1, layer1_dim, layer2_dim, \"critic\")\n",
        "        self.critic.compile(optimizer=adam_v2.Adam(learning_rate=alpha_C))\n",
        "        self.aloss= []\n",
        "        self.closs=[]\n",
        "\n",
        "    def choose_action(self, observation): #obs shape (1,2)\n",
        "        state = tf.convert_to_tensor([observation]) #state shape (1,1,2)\n",
        "        pars= self.actor(state) #mean and standard deviation that make action probs\n",
        "        pars= np.asarray(tf.squeeze(pars)).reshape(1,2)  \n",
        "        sigma , mu = np.hsplit(pars , 2)\n",
        "        sigma = tf.exp(sigma) #get rid of negative sigma\n",
        "        #sigma= abs(sigma)\n",
        "        action_probabilities = tfp.distributions.Normal(mu , sigma) #normal distribution with mu,sigma pars  \n",
        "        #log_prob = action_probabilities.log_prob(action_probabilities) #log (gonna be used for gradient)\n",
        "        action = action_probabilities.sample() #choose action (most likely to be chosen with higher probability)\n",
        "        action = tf.tanh(action) * 0.07 #action: continuous num in range(-0.07, 0.07)((-4,4) degree_\n",
        "        self.action = action  \n",
        "        return action #cast tensor to numpy(openAI gym doesnt take tensor)\n",
        "\n",
        "    # def save_models(self):\n",
        "    #     #print('... saving models ...')\n",
        "    #     self.actor.save_weights(self.actor.checkpoint_file)\n",
        "    #     self.critic.save_weights(self.critic.checkpoint_file)\n",
        "    # def load_models(self):\n",
        "    #     print('... loading models ...')\n",
        "    #     self.actor.load_weights(self.actor.checkpoint_file)\n",
        "    #     self.critic.load_weights(self.critic.checkpoint_file)\n",
        "        \n",
        "    def learn(self, state, reward, state_,done):\n",
        "        #print(\"state before \")\n",
        "        state = tf.convert_to_tensor([state], dtype=tf.float32)\n",
        "        state_ = tf.convert_to_tensor([state_], dtype=tf.float32)\n",
        "        reward = tf.convert_to_tensor(reward, dtype=tf.float32) # not fed to NN -> no need to reshape\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            state_value = self.critic(state)\n",
        "            state_value_ = self.critic(state_)\n",
        "            state_value = tf.squeeze(state_value) #squeeze Removes dims of size 1 from the shape of a tensor.\n",
        "            state_value_ = tf.squeeze(state_value_)\n",
        "            pars= self.actor(state)\n",
        "            #pars= np.asarray(tf.squeeze(pars)).reshape(1,2)\n",
        "            #mu , sigma= np.hsplit(pars , 2)\n",
        "            #mu = np.squeeze(mu)\n",
        "            #sigma = np.squeeze(sigma)\n",
        "            mu = pars[0,0]\n",
        "            sigma = pars[0,1]\n",
        "            #print(sigma)\n",
        "            #sigma = tf.exp(sigma)\n",
        "            #print(sigma)\n",
        "            action_probs = tfp.distributions.Normal(mu, abs(sigma)) #policy \n",
        "            log_prob = action_probs.log_prob(self.action[0,0] )\n",
        "            #print(mu,sigma)\n",
        "            #print(log_prob)\n",
        "                      \n",
        "            #TD error: \n",
        "            TD= self.gamma*state_value_*(1-int(done)) - state_value \n",
        "            delta = reward + TD #1-done: terminal stRemoves dimensions of size 1 from the shape of a tensor.ate zero effect \n",
        "            actor_loss = (-log_prob*delta)            \n",
        "            critic_loss = (delta**2) \n",
        "            #print(\"sig\", sigma , \"ac\", actor_loss, \"cr\", critic_loss)\n",
        "  \n",
        "            \n",
        "        gradient1 = tape.gradient(actor_loss, self.actor.trainable_variables)\n",
        "        \n",
        "        self.actor.optimizer.apply_gradients((grad , var) for (grad , var) in zip(gradient1, self.actor.trainable_variables) if grad is not None)\n",
        "        #if grad is not None\n",
        "            \n",
        "        gradient2 = tape.gradient(critic_loss, self.critic.trainable_variables)\n",
        "        self.critic.optimizer.apply_gradients((grad , var) for (grad , var) in zip(gradient2, self.critic.trainable_variables) if grad is not None)\n",
        "        # if grad is not None\n",
        "        return critic_loss, actor_loss, gradient1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "-7jAXNqRskpg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import shapely.geometry as geom\n",
        "from shapely.ops import nearest_points\n",
        "import math\n",
        "\n",
        "\n",
        "class lateralenv:\n",
        "    def __init__(self, data, data_length, n_episodes, episode_length):\n",
        "        # constants\n",
        "        dt = 0.01\n",
        "        vx = 10\n",
        "        iz = 2278.8\n",
        "        m = 1300\n",
        "        a1 = 1;\n",
        "        a2 = 1.5\n",
        "        caf = 60000\n",
        "        car = 60000\n",
        "        cb = -(caf + car);\n",
        "        cr = (-a1 * caf + a2 * car) / vx\n",
        "        db = -(a1 * caf - a2 * car);\n",
        "        dr = -(a1 ** 2 * caf + a2 ** 2 * car) / vx\n",
        "        cd = caf;\n",
        "        dd = a1 * caf\n",
        "        self.constants = [dt, vx, iz, m, cb, cr, db, dr, cd, dd]\n",
        "\n",
        "        self.data_length = data_length\n",
        "        self.n_episodes = n_episodes\n",
        "        self.episode_length = episode_length\n",
        "        self.episode_length_cnt = episode_length\n",
        "\n",
        "        self.road = data[0:data_length, :]\n",
        "        self.x = data[0:data_length, 0]\n",
        "        self.y = data[0:data_length, 1]\n",
        "        self.data_ep = []\n",
        "\n",
        "        self.heading_angle = [np.arctan2(self.y[i + 1] - self.y[i], self.x[i + 1] - self.x[i]) for i in\n",
        "                              range(self.data_length - 1)]  # rad [-1.57, 1.57]\n",
        "        self.heading_angle.insert(0, self.heading_angle[0])  # append last value to adjust the shape\n",
        "        self.heading_angle = np.asfarray(self.heading_angle).reshape(self.data_length, 1)\n",
        "\n",
        "        # ______________________________________________init vars_____________________________________________________________\n",
        "\n",
        "        self.score = 0\n",
        "        self.index = 0\n",
        "        self.Done = 0\n",
        "        self.coordinates = []\n",
        "        self.nearestPiontCheck = []\n",
        "        self.vys = []\n",
        "        self.vymax = -10\n",
        "        self.vars = np.zeros((5, 1))\n",
        "        self.vars_ = np.zeros((5, 1), dtype='float64')  # is only updated for normal step\n",
        "        self.vars_tmp = np.zeros((5, 1))  # is updated for both normal step and preview step\n",
        "\n",
        "    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "        self.n_episodes = 100\n",
        "        self.max_ep_length = 300  # could be int(data_length / n_episodes)\n",
        "\n",
        "        self.cnt = 0\n",
        "        self.dist_limit = 5\n",
        "        self.ang_limit1 = 0.79;\n",
        "        self.ang_limit2 = -0.79;  # 45 degree\n",
        "        self.bad_reward = 10\n",
        "        self.res = 8\n",
        "        self.b = 0  # for render\n",
        "        self.score_history = []\n",
        "        self.best_score = 0  # reward = 1/positive > 0 -> min score =0\n",
        "        self.load_checkpoint = False\n",
        "\n",
        "    def dist_diff(self, ep, limit_dist, limit_ang, stp, pre_point):  # =geom.Point(0,0)):\n",
        "        vy, r, x, y, psi = self.vars_tmp\n",
        "\n",
        "\n",
        "        # 3: based on car's vertical disance with the road\n",
        "        minus = self.data_ep - np.array((x, y)).reshape([1,2])\n",
        "        distarr = np.sqrt(minus[:, 0] ** 2 + minus[:, 1] ** 2)\n",
        "        ind = np.argmin(distarr)\n",
        "        #dist = np.min(distarr)\n",
        "        road_slope = (self.data_ep[ind+1, 1] - self.data_ep[ind, 1])/(self.data_ep[ind+1, 0] - self.data_ep[ind, 0]) if ind!=len(self.data_ep)-1 else (self.data_ep[ind, 1] - self.data_ep[ind-1, 1])/(self.data_ep[ind, 0] - self.data_ep[ind-1, 0])\n",
        "\n",
        "        point = geom.Point(x, y)\n",
        "        dist = point.distance(self.road_ep)\n",
        "        limited_dist = max(dist, 0.01)  # for makhraj problems\n",
        "\n",
        "        # limited_dist = min(limited_dist, 100)\n",
        "        # dist_z = math.sqrt((y - self.y0) ** 2 + (x - self.x0) ** 2)\n",
        "\n",
        "        nearestP = nearest_points(self.road_ep, point)[0]\n",
        "        self.nearestPiontCheck.append(np.array(nearestP))\n",
        "        self.nearestPiontCheck.append(np.array(point))\n",
        "        #road_slope = (nearestP.y - pre_point.y) / (nearestP.x - pre_point.x) if (nearestP.x - pre_point.x) != 0 else (nearestP.y - pre_point.y) / 0.001\n",
        "        angle_diff = abs(np.arctan2((road_slope - psi), 1))[0]\n",
        "        # angle_diff = abs(np.arctan2((nearestP.y-pre_point.y),nearestP.x-pre_point.x)- psi[0]) #sara\n",
        "\n",
        "        # index, = np.where(self.road_ep == nearestP)\n",
        "        # print(\"index\", index)\n",
        "        # angle_diff=  np.arctan2(self.road_ep[index+1][1]-self.road_ep[index][1], self.road_ep[index+1][0]- self.road_ep[index][0]) - psi\n",
        "        # angle_diff = abs((np.cos(x / 100) / 4 - psi)[0])\n",
        "        limited_angle_diff = max(angle_diff, 0.005)\n",
        "        # limited_angle_diff=min(limited_angle_diff , 100) #-> max reward = 5000, min reward 5e-5\n",
        "\n",
        "        if limit_dist == 1:\n",
        "            if limit_ang == 1:\n",
        "                return limited_dist, limited_angle_diff, nearestP\n",
        "            elif limit_ang == 0:\n",
        "                return limited_dist, angle_diff, nearestP\n",
        "        else:\n",
        "            return dist, angle_diff, nearestP\n",
        "\n",
        "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "    def preview(self, action,\n",
        "                preview):  # in this version the preview point is calculated using the updated self.vars. also try with non-updated vars\n",
        "        dt, vx, iz, m, cb, cr, db, dr, cd, dd = self.constants\n",
        "        vy, r, x, y, psi = np.vsplit(self.vars, 5)\n",
        "        if preview == 1:\n",
        "            dt = 0.3\n",
        "        if preview == 0:\n",
        "            dt = 0.1\n",
        "        # calc new state\n",
        "        par_mat1 = np.array([[cb / (m * vx), cr / m - vx, 0, 0, 0],\n",
        "                             [db / (iz * vx), dr / iz, 0, 0, 0],\n",
        "                             [-math.sin(psi), 0, 0, 0, 0],\n",
        "                             [math.cos(psi), 0, 0, 0, 0],\n",
        "                             [0, 1, 0, 0, 0]])\n",
        "\n",
        "        par_mat2 = np.array([[cd * action / m], [dd * action / iz], [vx * math.cos(psi)],\n",
        "                             [vx * math.sin(psi)], [0]], dtype='float64')\n",
        "\n",
        "        var_dot_mat = par_mat1 @ self.vars + par_mat2  # (5,1)= (5,5)@(5,1)+(5,1)\n",
        "        self.vars_tmp = self.vars + dt * var_dot_mat  # (5,1) =(5,1)+(5,1)\n",
        "\n",
        "        if preview == 0:\n",
        "            self.vars_ = self.vars_tmp\n",
        "\n",
        "        return\n",
        "\n",
        "    # +++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "    def normalize(self, d, a):\n",
        "        # return d/(dist_limit-0), a/(ang_limit1-ang_limit2)\n",
        "        return d / (self.dist_limit - 0), a\n",
        "\n",
        "    def step(self, action, stp_cnt, pre_point, ep_length):\n",
        "        self.preview(action, preview=0)\n",
        "        # print(\"____________________________NOT preview_________________________\")\n",
        "        dist, angle_diff, pre_point = lateralenv.dist_diff(self, ep=0, limit_dist=1, limit_ang=0, stp=stp_cnt,\n",
        "                                                           pre_point=pre_point)\n",
        "        #print(\"in step\", dist, angle_diff)\n",
        "        # dist, angle_diff= self.normalize(d=dist, a=angle_diff)\n",
        "        self.preview(action, preview=1)\n",
        "        # print(\"____________________________preview______________________________\")\n",
        "        future_dist, future_angle_diff, _ = lateralenv.dist_diff(self, ep=0, limit_dist=1, limit_ang=0,\n",
        "                                                                 stp=stp_cnt, pre_point=pre_point)\n",
        "        # future_dist, future_angle_diff= self.normalize( d= future_dist, a=future_angle_diff)\n",
        "\n",
        "        self.episode_length_cnt = self.episode_length_cnt - 1\n",
        "\n",
        "        if dist > self.dist_limit or angle_diff > self.ang_limit1 or angle_diff < self.ang_limit2 or self.episode_length_cnt == 0:\n",
        "            print(\"141 step :  dist\", dist, \"angle\", angle_diff)\n",
        "            self.Done = 1\n",
        "            # return self.vars_, self.state_,  bad_reward, 'nothing' , self.Done, pre_point\n",
        "            return None, None, self.bad_reward, 'nothing', self.Done, None\n",
        "        # %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% calc reward %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
        "\n",
        "        # 3: based on car's vertical disance with the road\n",
        "        else:\n",
        "            dist, angle_diff = self.normalize(d=dist, a=angle_diff)\n",
        "            future_dist, future_angle_diff = self.normalize(d=future_dist, a=future_angle_diff)\n",
        "            weight = 1\n",
        "            action_weight = -10\n",
        "            preview_weight = 0.01\n",
        "            # print(\"point\", point, dist, \"ang\", angle_diff)\n",
        "            # print(\"dist\", dist, \"ang\", angle_diff)\n",
        "            k1 = 1 / (dist ** 2 + angle_diff ** 2)\n",
        "            k2 = 1 / (future_dist ** 2 + future_angle_diff ** 2)\n",
        "            ep_len_weight = 1\n",
        "            reward_calc = f'{weight} * {k1} + {preview_weight}*{k2} + {action_weight} * {action} + {ep_len_weight} * {ep_length}'\n",
        "            # reward = - angle_diff\n",
        "\n",
        "            ## 4: Sarah test\n",
        "            # ------------------------\n",
        "            reward = k1 * weight + k2 * preview_weight + action_weight * action + ep_len_weight * (\n",
        "                        self.max_ep_length - self.episode_length_cnt)\n",
        "\n",
        "            # print(\"dist\", dist,\"angd\", angle_diff, \"p dist\",future_dist, \"p angd\", future_angle_diff)\n",
        "            self.state_ = np.array([dist, angle_diff, future_dist, future_angle_diff])  # real state (not limited)\n",
        "            # self.state_ = np.array([dist, angle_diff]) #real state (not limited)\n",
        "\n",
        "            # for next step\n",
        "            self.vars = self.vars_\n",
        "            self.coordinates.append(self.vars[2:4, 0])\n",
        "            self.vys.append(self.vars[0])\n",
        "\n",
        "            return self.vars_, self.state_, reward, reward_calc, self.Done, pre_point  # state:(dist, ang_dif)\n",
        "\n",
        "    # ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
        "\n",
        "    def render(self, ep, score, ep_length):\n",
        "        print(\"render\")\n",
        "        plt.xlabel(\"x\")\n",
        "        plt.ylabel(\"y\")\n",
        "        plt.plot(self.road_ep.coords.xy[0][:], self.road_ep.coords.xy[1][:], 'r')  # road\n",
        "        if ep_length != 0:\n",
        "            plt.plot(np.array(self.coordinates)[:, 0], np.array(self.coordinates)[:, 1], label=score)  # path\n",
        "            # b=1\n",
        "            if ep % 10 == 0:\n",
        "              # plt.legend()\n",
        "              #plt.show()\n",
        "              plt.savefig(f\"drive/MyDrive/RL_lane_following_debug/paths/path{ep}.jpg\")\n",
        "              plt.cla()\n",
        "              b = 0\n",
        "\n",
        "    def reset(self, ep_pointer):  # before each episode\n",
        "        self.Done = 0\n",
        "        self.episode_length_cnt = self.max_ep_length\n",
        "        self.coordinates = []\n",
        "        self.nearestPiontCheck = []\n",
        "\n",
        "        # a new section of the road excel is selected for each episode\n",
        "        self.data_ep = self.road[ep_pointer:ep_pointer + int(self.max_ep_length / self.res), :]\n",
        "        self.road_ep = geom.LineString(zip(self.x[ep_pointer: ep_pointer + int(self.max_ep_length / self.res)],\n",
        "                                           self.y[ep_pointer: ep_pointer + int(self.max_ep_length / self.res)]))  # 500*2\n",
        "\n",
        "        # the car starts on the road\n",
        "        st_vy = 0;\n",
        "        st_r = 0;\n",
        "        st_x = self.data_ep[0, 0]  # + np.random.rand()\n",
        "        # st_x = self.road[ep_pointer:ep_pointer+1,0]\n",
        "        st_y = self.data_ep[0, 1]  # + np.random.rand()\n",
        "        # st_y = self.road[ep_pointer+ep_pointer+1,1]\n",
        "        # st_psi = self.heading_angle[ep_pointer]  # + np.random.rand()*0.01\n",
        "        st_psi = (self.data_ep[1,1] - self.data_ep[0,1]) / (self.data_ep[1,0] - self.data_ep[0,0])\n",
        "        st_pre_point = geom.Point(st_x, st_y)\n",
        "\n",
        "        self.vars = np.array([[st_vy, st_r, st_x, st_y, st_psi]], dtype='float64').T\n",
        "        self.vars_tmp = np.array([[st_vy, st_r, st_x, st_y, st_psi]],\n",
        "                                 dtype='float64').T  # is updated for both normal step and preview step\n",
        "\n",
        "        # point0_ep = geom.Point(st_x, st_y)\n",
        "        limited_dist0, limited_angle_diff0, pre_p = self.dist_diff(ep=0, limit_dist=1, limit_ang=0, stp=0,\n",
        "                                                                   pre_point=st_pre_point)\n",
        "        limited_dist0, limited_angle_diff0 = self.normalize(limited_dist0, limited_angle_diff0)\n",
        "\n",
        "        self.preview(action=0, preview=1)\n",
        "        future_limited_dist0, future_limited_ang0, _ = self.dist_diff(ep=0, limit_dist=1, limit_ang=0, stp=0,\n",
        "                                                                      pre_point=pre_p)  # sefr\n",
        "        future_limited_dist0, future_limited_ang0 = self.normalize(future_limited_dist0, future_limited_ang0)\n",
        "\n",
        "        state0_ep = np.array([limited_dist0, limited_angle_diff0, future_limited_dist0, future_limited_ang0])  # (1,4)\n",
        "\n",
        "        return state0_ep, st_pre_point"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "gauHF6SIViZz",
        "outputId": "b0b9aeb2-7000-4f1e-9f76-3f0610d01b8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "import io\n",
        "\n",
        "uploaded = 'drive/MyDrive/RL_lane_following_debug/Chaos-generted road.csv'\n",
        "road = pd.read_csv(uploaded).to_numpy()\n",
        "plt.plot(road[0:114,0],road[0:114,1])\n",
        "plt.plot(road[114:350,0], road[114:350,1])\n",
        "plt.plot(road[350:423,0], road[350:423,1])\n",
        "plt.show()\n",
        "plt.savefig('drive/MyDrive/RL_lane_following_debug/tets.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fw_1Aum5snkq",
        "outputId": "6518a5e2-cd12-4bf2-b720-34092a4fd478"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "141 step :  dist 5.048910564308976 angle 0.18430513315016947\n",
            "episode 1 ep length  116 score [[358914.4]] avg_score 416340.72\n",
            "render\n",
            "141 step :  dist 5.050329461824296 angle 0.29820805963742897\n",
            "episode 2 ep length  41 score [[625426.06]] avg_score 336382.7\n",
            "render\n",
            "141 step :  dist 5.0994005668918945 angle 0.2573488910658289\n",
            "episode 3 ep length  45 score [[310618.12]] avg_score 270847.84\n",
            "render\n",
            "141 step :  dist 5.0267129553434575 angle 0.01939297252053332\n",
            "episode 4 ep length  147 score [[830745.44]] avg_score 508434.8\n",
            "render\n",
            "141 step :  dist 5.147283462041864 angle 0.28426590767683607\n",
            "episode 5 ep length  50 score [[265528.72]] avg_score 433300.7\n",
            "render\n",
            "141 step :  dist 5.020748723081532 angle 0.1969586856061524\n",
            "episode 6 ep length  63 score [[282381.16]] avg_score 390733.9\n",
            "render\n",
            "141 step :  dist 5.0008685704959595 angle 0.14192392888367772\n",
            "episode 7 ep length  53 score [[451916.28]] avg_score 369131.28\n",
            "render\n",
            "141 step :  dist 5.137210873887958 angle 0.017886018622031333\n",
            "episode 8 ep length  116 score [[298634.34]] avg_score 366291.9\n",
            "render\n",
            "141 step :  dist 5.038724428453976 angle 0.22571811342166023\n",
            "episode 9 ep length  30 score [[5008.0396]] avg_score 325759.75\n",
            "render\n",
            "141 step :  dist 5.034543870133435 angle 0.06898659156100334\n",
            "episode 10 ep length  68 score [[19950.084]] avg_score 294540.38\n",
            "render\n",
            "141 step :  dist 5.204884277828457 angle 0.3685208120687392\n",
            "episode 11 ep length  8 score [[153.53804]] avg_score 267765.1\n",
            "render\n",
            "141 step :  dist 5.2238878004710605 angle 0.2893584812283966\n",
            "episode 12 ep length  14 score [[479.23007]] avg_score 245456.92\n",
            "render\n",
            "141 step :  dist 5.259590238912016 angle 0.22309329061132172\n",
            "episode 13 ep length  60 score [[3153.7727]] avg_score 226721.17\n",
            "render\n",
            "141 step :  dist 5.161166978945781 angle 0.21937937297694993\n",
            "episode 14 ep length  13 score [[378.28632]] avg_score 210530.33\n",
            "render\n",
            "141 step :  dist 5.024689375962069 angle 0.23688667745072334\n",
            "episode 15 ep length  34 score [[1521.4888]] avg_score 196529.45\n",
            "render\n",
            "141 step :  dist 5.030311046072951 angle 0.34440758971600977\n",
            "episode 16 ep length  21 score [[1484.7268]] avg_score 184265.84\n",
            "render\n",
            "141 step :  dist 5.096011448881247 angle 0.5057138327840996\n",
            "episode 17 ep length  11 score [[299.9715]] avg_score 173428.62\n",
            "render\n",
            "141 step :  dist 5.334979195577251 angle 0.6250018066393973\n",
            "episode 18 ep length  18 score [[1724.6034]] avg_score 163810.94\n",
            "render\n",
            "141 step :  dist 5.374395630830773 angle 0.6249409470929628\n",
            "episode 19 ep length  46 score [[280083.53]] avg_score 161970.3\n",
            "render\n",
            "141 step :  dist 5.0581004823591 angle 0.5292596758068414\n",
            "episode 20 ep length  13 score [[472.77884]] avg_score 153874.84\n",
            "render\n",
            "141 step :  dist 5.072037535165012 angle 0.008768790614407789\n",
            "episode 21 ep length  20 score [[4712.8994]] avg_score 146592.36\n",
            "render\n",
            "141 step :  dist 5.016490162829209 angle 0.15256134699925464\n",
            "episode 22 ep length  68 score [[5683.723]] avg_score 140104.75\n",
            "render\n",
            "141 step :  dist 5.04004187815685 angle 0.30784502799699487\n",
            "episode 23 ep length  11 score [[300.31458]] avg_score 134014.67\n",
            "render\n",
            "141 step :  dist 5.112756110001573 angle 0.22308528185867058\n",
            "episode 24 ep length  36 score [[1280.2109]] avg_score 128449.94\n",
            "render\n",
            "141 step :  dist 5.6287970097950355 angle 0.45356775424252666\n",
            "episode 25 ep length  8 score [[133.90819]] avg_score 123312.37\n",
            "render\n",
            "141 step :  dist 5.3005007344890265 angle 0.22394794260766465\n",
            "episode 26 ep length  15 score [[454.7371]] avg_score 118572.21\n",
            "render\n",
            "141 step :  dist 5.112323746046219 angle 0.06526466168729182\n",
            "episode 27 ep length  21 score [[1171.9667]] avg_score 114189.76\n",
            "render\n",
            "141 step :  dist 5.440356622673639 angle 0.3422301399094413\n",
            "episode 28 ep length  16 score [[845.79645]] avg_score 110116.38\n",
            "render\n",
            "141 step :  dist 5.250195820963579 angle 0.03371835349081569\n",
            "episode 29 ep length  24 score [[1055.1184]] avg_score 106328.0\n",
            "render\n",
            "141 step :  dist 5.104061982918648 angle 0.24500010609477588\n",
            "episode 30 ep length  52 score [[3388.4407]] avg_score 102842.47\n",
            "render\n",
            "141 step :  dist 5.125314180532459 angle 0.11691491219037362\n",
            "episode 31 ep length  38 score [[3256.525]] avg_score 99564.89\n",
            "render\n",
            "141 step :  dist 5.076425730390821 angle 0.3466924690572823\n",
            "episode 32 ep length  10 score [[250.54549]] avg_score 96454.266\n",
            "render\n",
            "141 step :  dist 5.178496954307551 angle 0.2573971478143555\n",
            "episode 33 ep length  17 score [[786.5195]] avg_score 93535.46\n",
            "render\n",
            "141 step :  dist 5.087562112042031 angle 0.5944757148199115\n",
            "episode 34 ep length  9 score [[182.84993]] avg_score 90784.91\n",
            "render\n",
            "141 step :  dist 5.754194378687639 angle 0.7416348472938056\n",
            "episode 35 ep length  16 score [[1765.9927]] avg_score 88199.125\n",
            "render\n",
            "141 step :  dist 5.547599199404716 angle 0.5744199947864704\n",
            "episode 36 ep length  45 score [[265809.9]] avg_score 89071.77\n",
            "render\n",
            "141 step :  dist 5.187132666317097 angle 0.24749543952626557\n",
            "episode 37 ep length  43 score [[272859.25]] avg_score 89835.49\n",
            "render\n",
            "141 step :  dist 5.188496680188124 angle 0.21490546783216102\n",
            "episode 38 ep length  52 score [[502514.5]] avg_score 94347.914\n",
            "render\n",
            "141 step :  dist 1.1382851965085758 angle 1.0454341559577693\n",
            "episode 39 ep length  20 score [[260490.94]] avg_score 93264.586\n",
            "render\n",
            "141 step :  dist 5.367633167707443 angle 0.0808816807199406\n",
            "episode 40 ep length  6 score [[85.27096]] avg_score 90933.11\n",
            "render\n",
            "141 step :  dist 5.990931409051335 angle 0.0008785707104591999\n",
            "episode 41 ep length  5 score [[51.66146]] avg_score 88715.29\n",
            "render\n",
            "141 step :  dist 3.7887085129278217 angle 1.556095801371249\n",
            "episode 42 ep length  8 score [[231.58913]] avg_score 86603.46\n",
            "render\n",
            "141 step :  dist 5.099026234391783 angle 0.43557841237351946\n",
            "episode 43 ep length  17 score [[1225.7878]] avg_score 84594.27\n",
            "render\n",
            "141 step :  dist 5.122856471463299 angle 0.2482902290194882\n",
            "episode 44 ep length  42 score [[7411.6445]] avg_score 82742.43\n",
            "render\n",
            "141 step :  dist 0.277910540701359 angle 0.7911002990801522\n",
            "episode 45 ep length  126 score [[266996.2]] avg_score 88379.6\n",
            "render\n",
            "141 step :  dist 5.000610735858746 angle 0.012438573516218066\n",
            "episode 46 ep length  4 score [[45.420624]] avg_score 86458.34\n",
            "render\n",
            "141 step :  dist 5.327460914746614 angle 0.4036261915625704\n",
            "episode 47 ep length  35 score [[677919.5]] avg_score 89667.14\n",
            "render\n",
            "141 step :  dist 0.04300453574818859 angle 1.4308678041610374\n",
            "episode 48 ep length  30 score [[454066.3]] avg_score 90636.98\n",
            "render\n",
            "141 step :  dist 5.993997801931064 angle 0.05630588119789118\n",
            "episode 49 ep length  5 score [[53.340195]] avg_score 88787.3\n",
            "render\n",
            "141 step :  dist 5.426592078272974 angle 0.03233041691925906\n",
            "episode 50 ep length  8 score [[138.67184]] avg_score 87011.77\n",
            "render\n",
            "141 step :  dist 5.837228819980178 angle 0.01934222986124633\n",
            "episode 51 ep length  5 score [[53.03694]] avg_score 85305.7\n",
            "render\n",
            "141 step :  dist 0.7794420753918073 angle 1.2846276301654025\n",
            "episode 52 ep length  10 score [[8672.221]] avg_score 83681.88\n",
            "render\n",
            "141 step :  dist 5.999181519080656 angle 0.06952290456187385\n",
            "episode 53 ep length  5 score [[49.528816]] avg_score 82103.03\n",
            "render\n",
            "141 step :  dist 3.2732580522302643 angle 1.5605178831572009\n",
            "episode 54 ep length  8 score [[347.9983]] avg_score 80583.12\n",
            "render\n",
            "141 step :  dist 5.000532496893947 angle 0.02419353548031886\n",
            "episode 55 ep length  4 score [[46.52689]] avg_score 79118.01\n",
            "render\n",
            "141 step :  dist 0.66282941915224 angle 1.550784711510659\n",
            "episode 56 ep length  7 score [[8621.824]] avg_score 77715.984\n",
            "render\n",
            "141 step :  dist 4.023965107258869 angle 1.541196793440479\n",
            "episode 57 ep length  8 score [[212.29565]] avg_score 76352.84\n",
            "render\n",
            "141 step :  dist 5.000274631159227 angle 0.0037827742819905737\n",
            "episode 58 ep length  4 score [[45.616188]] avg_score 75036.445\n",
            "render\n",
            "141 step :  dist 6.000273172129585 angle 0.03068706232100711\n",
            "episode 59 ep length  5 score [[50.85072]] avg_score 73764.69\n",
            "render\n",
            "141 step :  dist 0.2887927551155221 angle 1.5518013228967262\n",
            "episode 60 ep length  7 score [[48383.438]] avg_score 72591.73\n",
            "render\n",
            "141 step :  dist 5.000389003698455 angle 0.02140282435675642\n",
            "episode 61 ep length  4 score [[44.87883]] avg_score 71401.73\n",
            "render\n",
            "141 step :  dist 5.000384189703854 angle 0.01828435520758305\n",
            "episode 62 ep length  4 score [[45.205105]] avg_score 70250.12\n",
            "render\n",
            "141 step :  dist 5.000422805705975 angle 0.01813728742928876\n",
            "episode 63 ep length  4 score [[44.977787]] avg_score 69135.07\n",
            "render\n",
            "141 step :  dist 2.769571942198678 angle 1.5022138042920108\n",
            "episode 64 ep length  9 score [[479.0347]] avg_score 68055.49\n",
            "render\n",
            "141 step :  dist 5.9988733534227325 angle 0.07912404785896737\n",
            "episode 65 ep length  5 score [[49.217163]] avg_score 67008.52\n",
            "render\n",
            "141 step :  dist 5.000273156041942 angle 0.05018418383639489\n",
            "episode 66 ep length  4 score [[44.24926]] avg_score 65993.27\n",
            "render\n",
            "141 step :  dist 5.000154778563001 angle 0.022155802146243988\n",
            "episode 67 ep length  4 score [[44.976208]] avg_score 65008.33\n",
            "render\n",
            "141 step :  dist 5.485407763037311 angle 0.086082643534755\n",
            "episode 68 ep length  5 score [[57.63502]] avg_score 64052.367\n",
            "render\n",
            "141 step :  dist 5.000937971222356 angle 0.05031330283618559\n",
            "episode 69 ep length  4 score [[44.350166]] avg_score 63124.1\n",
            "render\n",
            "141 step :  dist 5.176033353234906 angle 0.35329827072596615\n",
            "episode 70 ep length  11 score [[308.62708]] avg_score 62222.812\n",
            "render\n",
            "141 step :  dist 5.3585074591870185 angle 0.7502127566448235\n",
            "episode 71 ep length  7 score [[115.6804]] avg_score 61346.55\n",
            "render\n",
            "141 step :  dist 5.397407805500051 angle 0.4583781627020223\n",
            "episode 72 ep length  17 score [[1569.7201]] avg_score 60498.207\n",
            "render\n",
            "141 step :  dist 5.0555147578455 angle 0.6361180005970843\n",
            "episode 73 ep length  37 score [[6241.7866]] avg_score 59701.1\n",
            "render\n",
            "141 step :  dist 0.2669512463439503 angle 1.1784072868945115\n",
            "episode 74 ep length  10 score [[277880.]] avg_score 59269.844\n",
            "render\n",
            "141 step :  dist 5.363755777502301 angle 0.009129247016047132\n",
            "episode 75 ep length  5 score [[60.361073]] avg_score 58479.62\n",
            "render\n",
            "141 step :  dist 5.132933001113766 angle 0.44167287217460927\n",
            "episode 76 ep length  33 score [[299120.47]] avg_score 59008.96\n",
            "render\n",
            "141 step :  dist 5.0181860768113165 angle 0.3851441590726093\n",
            "episode 77 ep length  22 score [[2695.5178]] avg_score 58250.312\n",
            "render\n",
            "141 step :  dist 5.001889525553232 angle 0.2755530866730283\n",
            "episode 78 ep length  49 score [[72506.62]] avg_score 57959.0\n",
            "render\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2f7ffeeb6b48>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0;31m# if not load_checkpoint:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m             \u001b[0;31m# log\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mep_pointer\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mep_length\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"{ep} / {ep_length}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-c91b79479de5>\u001b[0m in \u001b[0;36mlearn\u001b[0;34m(self, state, reward, state_, done)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mgradient1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;31m#if grad is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    663\u001b[0m             f\"strategy={strategy}.\")\n\u001b[1;32m    664\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 665\u001b[0;31m       \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    666\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mexperimental_aggregate_gradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    667\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transform_unaggregated_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m    942\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    943\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 944\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    948\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"learning_rate\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hyper\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m       \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decayed_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m       \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"lr_t\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr_t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_decayed_lr\u001b[0;34m(self, var_dtype)\u001b[0m\n\u001b[1;32m   1004\u001b[0m     \u001b[0;34m\"\"\"Get decayed learning rate as a Tensor with dtype=var_dtype.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1005\u001b[0m     \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_hyper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"learning_rate\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate_schedule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLearningRateSchedule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m       \u001b[0mlocal_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m       \u001b[0mlr_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr_t\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "#from Agent import Agent\n",
        "#from lateralenv import lateralenv\n",
        "import xlsxwriter\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import shapely.geometry as geom\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# if __name__ == '__main__':\n",
        "discreate_road_pd = pd.read_csv('drive/MyDrive/RL_lane_following_debug/Chaos-generted road.csv')\n",
        "road = discreate_road_pd.to_numpy()\n",
        "\n",
        "agent = Agent(layer1_dim=128, layer2_dim=64, n_actions=2, alpha_A=0.0003, alpha_C=0.005, gamma=0.99)\n",
        "n_episodes = 100\n",
        "data_length = int(road.shape[0] / 10)  # 10,000\n",
        "max_ep_length = 300  # could be int(data_length / n_episodes)\n",
        "env = lateralenv(road, data_length, n_episodes, max_ep_length)\n",
        "\n",
        "cnt = 0\n",
        "dist_limit = 5\n",
        "ang_limit1 = 0.79;\n",
        "ang_limit2 = -0.79;  # 45 degree\n",
        "bad_reward = 10\n",
        "res = 8\n",
        "b = 0  # for render\n",
        "score_history = []\n",
        "best_score = 0  # reward = 1/positive > 0 -> min score =0\n",
        "load_checkpoint = False\n",
        "\n",
        "workbook = xlsxwriter.Workbook('log.xlsx')\n",
        "log = workbook.add_worksheet(\"ep_per_ep\")\n",
        "log.write(0, 0, \"ep / step\")\n",
        "log.write(0, 3, \"vy\")\n",
        "log.write(0, 4, \"point\")\n",
        "log.write(0, 5, \"distance\")\n",
        "log.write(0, 6, \"angle_diff\")\n",
        "log.write(0, 7, \"road derivative\")\n",
        "log.write(0, 8, \"psi\")\n",
        "log.write(0, 9, \"reward\")\n",
        "log.write(0, 10, \"point dist_diff +  preview point dist_diff + action\")\n",
        "\n",
        "# training________________________________________________________________________________________\n",
        "ep_pointer = 0\n",
        "for ep in range(1, n_episodes + 1):\n",
        "    score = 0\n",
        "    al = [];\n",
        "    cl = [];\n",
        "    rewards = []\n",
        "    # print(\"b4 reset\")\n",
        "    state, pre_point = env.reset(ep_pointer)  # (1,2)\n",
        "    # print(\"after reset state\", state)\n",
        "    states_ = []\n",
        "    ep_length = 0\n",
        "    # print(ep, \":____________________________________________________________________________\")\n",
        "    while True:\n",
        "        action = agent.choose_action(state)\n",
        "        # assert action != act_buffer , \"equal actions !!\"\n",
        "        # act_buffer = action\n",
        "\n",
        "        newvars, state_, reward, reward_calc, Done, pre_point = env.step(action, ep_length, pre_point, ep_length)\n",
        "\n",
        "        if Done == 1:\n",
        "            break\n",
        "        # if ep_length >100:\n",
        "        #   break\n",
        "        else:\n",
        "            states_.append(state_)\n",
        "            reward = tf.get_static_value(reward)\n",
        "            score = score + reward\n",
        "            rewards.append(reward)\n",
        "\n",
        "            # if not load_checkpoint:\n",
        "            closs, aloss, grad1 = agent.learn(state, reward, state_, Done)\n",
        "            # log\n",
        "            log.write(ep_pointer + ep_length + 1, 0, f\"{ep} / {ep_length}\")\n",
        "            log.write(ep_pointer + ep_length + 1, 3, newvars[0])\n",
        "            log.write(ep_pointer + ep_length + 1, 4, str(newvars[2:4]))\n",
        "            log.write(ep_pointer + ep_length + 1, 5, state_[0])\n",
        "            log.write(ep_pointer + ep_length + 1, 6, state_[1])\n",
        "            log.write(ep_pointer + ep_length + 1, 7, np.cos(newvars[2] / 200)[0] / 4)\n",
        "            log.write(ep_pointer + ep_length + 1, 8, newvars[-1])\n",
        "            log.write(ep_pointer + ep_length + 1, 9, reward)\n",
        "            log.write(ep_pointer + ep_length + 1, 10, reward_calc)\n",
        "\n",
        "            state = state_\n",
        "            ep_length += 1  # step counter\n",
        "\n",
        "    states_ = np.array(states_)\n",
        "    score_history.append(score * ep_length / 100)  # ep length should affect score\n",
        "    ep_pointer += max(int(ep_length / res), 1)\n",
        "\n",
        "    avg_score = np.mean(score_history[-100:])\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "    if (ep % 1 == 0):\n",
        "        print('episode', ep, 'ep length ', ep_length, 'score', score, 'avg_score', avg_score)\n",
        "        env.render(ep, score, ep_length)\n",
        "\n",
        "workbook.close()\n",
        "\n",
        "if not load_checkpoint:\n",
        "    ep = [i + 1 for i in range(n_episodes)]\n",
        "    x = np.array(ep).reshape(n_episodes, 1)\n",
        "    score_history = np.array(score_history).reshape(n_episodes, 1)\n",
        "    plt.xlabel(\"episode\")\n",
        "    plt.ylabel(\"score\")\n",
        "    plt.plot(x, score_history)\n",
        "    plt.savefig('scores.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Trps2XXUlHf"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mmPtNVj3Px5c"
      },
      "outputs": [],
      "source": [
        "# test \n",
        "import numpy as np \n",
        "import math\n",
        "import shapely.geometry as geom\n",
        "import matplotlib.pyplot as plt\n",
        "from shapely.ops import nearest_points\n",
        "\n",
        "# x= np.arange(0, 10).reshape(10, 1) \n",
        "# y= 50*np.sin(x/200)\n",
        "# road = geom.LineString(zip(x,y))\n",
        "# p= geom.Point(314,50)\n",
        "# print(\"ggg\", p.coords[0][1])\n",
        "# print(\"ggg\", p.coords[0][0])\n",
        "# dist = p.distance(road) \n",
        "# print(dist)\n",
        "# nearestP = nearest_points(road, p)\n",
        "# print(nearestP[0])\n",
        "#angle_diff= np.arctan2(nearestP.centroid.y, nearestP.centroid.x) - self.psi0 #pos/neg mide  \n",
        "\n",
        "n= 25000\n",
        "x= np.arange(0, n).reshape(n, 1) \n",
        "y= 50*np.sin(x/100)\n",
        "plt.plot(x,y)\n",
        "#self.road = geom.LineString(zip(x,y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CWXkoLX8O5X",
        "outputId": "3c82c96e-868a-4a4a-ce95-bf7b24074593"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2\n",
            "4\n",
            "8\n",
            "4\n",
            "8\n",
            "2\n",
            "4\n"
          ]
        }
      ],
      "source": [
        "for i in range(2):\n",
        "   print(\"2\")\n",
        "   for j in range(2):\n",
        "     print(4)\n",
        "     if i==1:\n",
        "       break\n",
        "     else:\n",
        "       print(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tq3t-zxXy585"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "terminate.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNcWZJsit7Fyei/pbECnC61",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}